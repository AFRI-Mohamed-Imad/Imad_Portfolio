def get_experience():
    experiences = [
        {
            "title": "Data Engineer | Private Equity Cube",
            "details": [
                "Support quotidien sur l’utilisation de l’application, gestion des incidents via les mails des clients, analyse des pannes, et création de tickets Jira détaillés pour les développeurs.",
                "Enquête approfondie sur les problématiques pour garantir la satisfaction client et l’efficacité de l’orchestration des flux.",
                "Développement d’une solution automatisée basée sur NLP et NER pour classifier les documents sensibles (CIN, RIB, documents de souscription).",
                "Extraction des données sensibles des documents clients pour une intégration directe dans l’application.",
                "Conception et implémentation d’une pipeline pour le traitement et la migration des données personnelles des clients vers MySQL.",
                "Création de dashboards interactifs dans PowerBI et Metabase pour le reporting des KPIs clients.",
                "Intégration de solutions Big Data et Cloud, avec un benchmark technique pour choisir et utiliser efficacement Azure.",
                "Amélioration des flux de travail liés au Private Equity en tirant parti de l’infrastructure Cloud et des outils Big Data."
            ],
        },
        {
            "title": "Data Engineer Intern | BPCE Assurances",
            "details": [
                "Conception et développement d’une base de données complète des habitations en France, incluant des données géographiques et des informations sur les risques naturels.",
                "Collecte et traitement de données open data et intégration de ces données dans GCP.",
                "Développement de modèles prédictifs (XGBoost) pour combler les données manquantes, comme le nombre de pièces ou la surface des habitations, à partir d’images aériennes et d’autres données contextuelles.",
                "Utilisation de MLflow pour gérer le cycle de vie des modèles (versioning, suivi des performances).",
                "Migration des données sensibles vers GCP tout en garantissant leur sécurité et leur accessibilité.",
                "Mise en place de flux de données automatisés avec Cloud Composer pour une gestion efficace des pipelines.",
                "Création de tableaux de bord PowerBI pour visualiser les données et faciliter leur interprétation par les équipes métier.",
                "Automatisation des analyses pour soutenir les processus décisionnels des assureurs."
            ],
        },
        {
            "title": "Data Scientist Intern | BNP Paribas",
            "details": [
                "Développement de modèles prédictifs pour estimer les taux de financement en France et au Maroc, en intégrant des variables économiques et financières.",
                "Validation des modèles pour garantir leur robustesse et leur précision dans des contextes variés.",
                "Création d’un système de classification basé sur des critères financiers pour évaluer l’éligibilité des dossiers de financement.",
                "Optimisation des algorithmes pour améliorer la rapidité et l’efficacité du traitement des dossiers.",
                "Conception et implémentation de tableaux de bord interactifs sous PowerBI et Tableau pour présenter les résultats aux équipes non techniques.",
                "Automatisation des rapports pour garantir un accès rapide et régulier aux informations clés.",
                "Participation active aux réunions avec les équipes métiers pour affiner les exigences et aligner les livrables avec les objectifs stratégiques."
            ],
        },
    ]
    return experiences
